{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ea7142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Cell 2: Imports\n",
    "# ---------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa7fb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Math: (395, 41) (395,)\n",
      "Portuguese: (649, 41) (649,)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Cell 3: Load & preprocess data\n",
    "# ---------------------------\n",
    "math = pd.read_csv(\"student-mat.csv\", sep=\",\")\n",
    "por = pd.read_csv(\"student-por.csv\", sep=\";\")\n",
    "\n",
    "# One-hot encode categoricals consistently\n",
    "full = pd.concat([math, por])\n",
    "full = pd.get_dummies(full, drop_first=True)\n",
    "\n",
    "# Separate back into math and portuguese\n",
    "math_enc = full.iloc[:len(math), :]\n",
    "por_enc = full.iloc[len(math):, :]\n",
    "\n",
    "X_math = math_enc.drop(\"G3\", axis=1).values\n",
    "y_math = math_enc[\"G3\"].values\n",
    "X_por = por_enc.drop(\"G3\", axis=1).values\n",
    "y_por = por_enc[\"G3\"].values\n",
    "\n",
    "print(\"Math:\", X_math.shape, y_math.shape)\n",
    "print(\"Portuguese:\", X_por.shape, y_por.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b303e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Cell 4: Build simple networks\n",
    "# ---------------------------\n",
    "input_dim = X_por.shape[1]\n",
    "hidden_dim = 64\n",
    "ensemble_size = 3\n",
    "\n",
    "# Feature extractor\n",
    "feature_extractor = nn.Sequential(\n",
    "    nn.Linear(input_dim, hidden_dim),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_dim, hidden_dim//2),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "# Ensemble of predictors\n",
    "predictors = [nn.Sequential(\n",
    "    nn.Linear(hidden_dim//2, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 1)\n",
    ") for _ in range(ensemble_size)]\n",
    "\n",
    "# Domain discriminator\n",
    "domain_disc = nn.Sequential(\n",
    "    nn.Linear(hidden_dim//2, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 2)  # source=0, target=1\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "feature_extractor.to(device)\n",
    "for p in predictors: p.to(device)\n",
    "domain_disc.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bb414d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Cell 5: Gradient reversal trick\n",
    "# ---------------------------\n",
    "class GRL(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lambda_):\n",
    "        ctx.lambda_ = lambda_\n",
    "        return x.view_as(x)\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return -ctx.lambda_ * grad_output, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea96b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b63f7c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hd=64, lambda=0.1, dropout=0.2] RMSE=2.6898, MAE=1.6795, R²=0.6544\n",
      "[hd=64, lambda=0.1, dropout=0.3] RMSE=2.7589, MAE=1.7429, R²=0.6364\n",
      "[hd=64, lambda=0.1, dropout=0.5] RMSE=3.4184, MAE=2.5705, R²=0.4419\n",
      "[hd=64, lambda=0.3, dropout=0.2] RMSE=2.6166, MAE=1.5953, R²=0.6730\n",
      "[hd=64, lambda=0.3, dropout=0.3] RMSE=2.8910, MAE=1.8095, R²=0.6008\n",
      "[hd=64, lambda=0.3, dropout=0.5] RMSE=3.2037, MAE=2.2130, R²=0.5098\n",
      "[hd=64, lambda=0.5, dropout=0.2] RMSE=2.5980, MAE=1.6043, R²=0.6776\n",
      "[hd=64, lambda=0.5, dropout=0.3] RMSE=2.7144, MAE=1.6733, R²=0.6481\n",
      "[hd=64, lambda=0.5, dropout=0.5] RMSE=3.8035, MAE=3.0718, R²=0.3090\n",
      "[hd=64, lambda=1.0, dropout=0.2] RMSE=2.6733, MAE=1.6558, R²=0.6587\n",
      "[hd=64, lambda=1.0, dropout=0.3] RMSE=2.8071, MAE=1.8509, R²=0.6236\n",
      "[hd=64, lambda=1.0, dropout=0.5] RMSE=3.6959, MAE=2.9254, R²=0.3476\n",
      "[hd=128, lambda=0.1, dropout=0.2] RMSE=2.7146, MAE=1.6695, R²=0.6480\n",
      "[hd=128, lambda=0.1, dropout=0.3] RMSE=2.6789, MAE=1.6362, R²=0.6572\n",
      "[hd=128, lambda=0.1, dropout=0.5] RMSE=2.8270, MAE=1.7328, R²=0.6183\n",
      "[hd=128, lambda=0.3, dropout=0.2] RMSE=2.6545, MAE=1.6382, R²=0.6634\n",
      "[hd=128, lambda=0.3, dropout=0.3] RMSE=2.7879, MAE=1.7141, R²=0.6288\n",
      "[hd=128, lambda=0.3, dropout=0.5] RMSE=2.6874, MAE=1.6353, R²=0.6550\n",
      "[hd=128, lambda=0.5, dropout=0.2] RMSE=2.7473, MAE=1.6565, R²=0.6395\n",
      "[hd=128, lambda=0.5, dropout=0.3] RMSE=2.7007, MAE=1.6251, R²=0.6516\n",
      "[hd=128, lambda=0.5, dropout=0.5] RMSE=2.8322, MAE=1.7022, R²=0.6169\n",
      "[hd=128, lambda=1.0, dropout=0.2] RMSE=2.8394, MAE=1.7574, R²=0.6149\n",
      "[hd=128, lambda=1.0, dropout=0.3] RMSE=2.5460, MAE=1.5501, R²=0.6904\n",
      "[hd=128, lambda=1.0, dropout=0.5] RMSE=2.7858, MAE=1.6763, R²=0.6293\n",
      "[hd=256, lambda=0.1, dropout=0.2] RMSE=2.7188, MAE=1.6374, R²=0.6469\n",
      "[hd=256, lambda=0.1, dropout=0.3] RMSE=2.8134, MAE=1.6946, R²=0.6219\n",
      "[hd=256, lambda=0.1, dropout=0.5] RMSE=2.6865, MAE=1.6402, R²=0.6553\n",
      "[hd=256, lambda=0.3, dropout=0.2] RMSE=2.6258, MAE=1.6106, R²=0.6707\n",
      "[hd=256, lambda=0.3, dropout=0.3] RMSE=2.8451, MAE=1.7248, R²=0.6134\n",
      "[hd=256, lambda=0.3, dropout=0.5] RMSE=2.6557, MAE=1.6093, R²=0.6631\n",
      "[hd=256, lambda=0.5, dropout=0.2] RMSE=2.7407, MAE=1.6730, R²=0.6412\n",
      "[hd=256, lambda=0.5, dropout=0.3] RMSE=2.7359, MAE=1.6606, R²=0.6425\n",
      "[hd=256, lambda=0.5, dropout=0.5] RMSE=2.5496, MAE=1.5384, R²=0.6895\n",
      "[hd=256, lambda=1.0, dropout=0.2] RMSE=2.6730, MAE=1.6233, R²=0.6587\n",
      "[hd=256, lambda=1.0, dropout=0.3] RMSE=2.6857, MAE=1.6260, R²=0.6555\n",
      "[hd=256, lambda=1.0, dropout=0.5] RMSE=2.6350, MAE=1.5904, R²=0.6684\n",
      "\n",
      "Best config:\n",
      "hidden_dim=128, lambda=1.0, dropout=0.3 -> RMSE=2.5460, MAE=1.5501, R²=0.6904\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Cell 6: Hyperparameter tuning with grid search\n",
    "# ---------------------------\n",
    "\n",
    "def train_dann_once(X_src, y_src, X_tgt, \n",
    "                    hidden_dim=128, \n",
    "                    epochs=200, \n",
    "                    batch_size=32, \n",
    "                    lambda_adv=0.5, \n",
    "                    dropout_rate=0.3):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    scaler = StandardScaler()\n",
    "    X_src = scaler.fit_transform(X_src)\n",
    "    X_tgt = scaler.transform(X_tgt)\n",
    "\n",
    "    X_src_t = torch.tensor(X_src, dtype=torch.float32)\n",
    "    y_src_t = torch.tensor(y_src, dtype=torch.float32).view(-1,1)\n",
    "    X_tgt_t = torch.tensor(X_tgt, dtype=torch.float32)\n",
    "\n",
    "    src_loader = DataLoader(TensorDataset(X_src_t, y_src_t), batch_size=batch_size, shuffle=True)\n",
    "    tgt_loader = DataLoader(TensorDataset(X_tgt_t, torch.zeros(len(X_tgt_t),1)), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Feature extractor with dropout\n",
    "    feature_extractor = nn.Sequential(\n",
    "        nn.Linear(X_src.shape[1], hidden_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout_rate),\n",
    "        nn.Linear(hidden_dim, hidden_dim//2),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout_rate)\n",
    "    ).to(device)\n",
    "\n",
    "    # Ensemble of predictors\n",
    "    ensemble_size = 3\n",
    "    predictors = [\n",
    "        nn.Sequential(\n",
    "            nn.Linear(hidden_dim//2, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        ).to(device)\n",
    "        for _ in range(ensemble_size)\n",
    "    ]\n",
    "\n",
    "    # Domain discriminator\n",
    "    domain_disc = nn.Sequential(\n",
    "        nn.Linear(hidden_dim//2, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 2)\n",
    "    ).to(device)\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    opt_f = optim.Adam(feature_extractor.parameters(), lr=1e-3)\n",
    "    opt_p = optim.Adam(chain(*[p.parameters() for p in predictors]), lr=1e-3)\n",
    "    opt_d = optim.Adam(domain_disc.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for (xs, ys), (xt, _) in zip(src_loader, tgt_loader):\n",
    "            xs, ys, xt = xs.to(device), ys.to(device), xt.to(device)\n",
    "\n",
    "            # Extract features\n",
    "            zs = feature_extractor(xs)\n",
    "            zt = feature_extractor(xt)\n",
    "\n",
    "            # --- Label loss ---\n",
    "            preds = [p(zs) for p in predictors]\n",
    "            preds_mean = torch.mean(torch.stack(preds), dim=0)\n",
    "            loss_label = mse_loss(preds_mean, ys)\n",
    "\n",
    "            # --- Domain loss ---\n",
    "            z_all = torch.cat([zs, zt], dim=0)\n",
    "            d_labels = torch.cat([torch.zeros(len(zs)), torch.ones(len(zt))]).long().to(device)\n",
    "\n",
    "            z_rev = GRL.apply(z_all, lambda_adv)\n",
    "            d_preds = domain_disc(z_rev)\n",
    "            loss_domain = ce_loss(d_preds, d_labels)\n",
    "\n",
    "            loss_total = loss_label + loss_domain\n",
    "\n",
    "            # Backprop\n",
    "            opt_f.zero_grad(); opt_p.zero_grad(); opt_d.zero_grad()\n",
    "            loss_total.backward()\n",
    "            opt_f.step(); opt_p.step(); opt_d.step()\n",
    "\n",
    "    return feature_extractor, predictors, scaler\n",
    "\n",
    "\n",
    "def evaluate(feat, predictors, scaler, X_test, y_test):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    feat.eval()\n",
    "    for p in predictors: p.eval()\n",
    "\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_test_t = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test = y_test\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z = feat(X_test_t)\n",
    "        preds = [p(z).cpu().numpy().flatten() for p in predictors]\n",
    "        preds_mean = np.mean(preds, axis=0)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds_mean))\n",
    "    mae = mean_absolute_error(y_test, preds_mean)\n",
    "    r2 = r2_score(y_test, preds_mean)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Run grid search\n",
    "# ---------------------------\n",
    "hidden_dims = [64, 128, 256]\n",
    "lambda_vals = [0.1, 0.3, 0.5, 1.0]\n",
    "dropouts = [0.2, 0.3, 0.5]\n",
    "\n",
    "results = []\n",
    "\n",
    "for hd in hidden_dims:\n",
    "    for lam in lambda_vals:\n",
    "        for dr in dropouts:\n",
    "            feat, preds, scaler = train_dann_once(X_por, y_por, X_math, \n",
    "                                                  hidden_dim=hd, \n",
    "                                                  epochs=200, \n",
    "                                                  lambda_adv=lam, \n",
    "                                                  dropout_rate=dr)\n",
    "            rmse, mae, r2 = evaluate(feat, preds, scaler, X_math, y_math)\n",
    "            results.append((hd, lam, dr, rmse, mae, r2))\n",
    "            print(f\"[hd={hd}, lambda={lam}, dropout={dr}] RMSE={rmse:.4f}, MAE={mae:.4f}, R²={r2:.4f}\")\n",
    "\n",
    "# Show best setting\n",
    "best = sorted(results, key=lambda x: x[3])[0]  # sort by RMSE\n",
    "print(\"\\nBest config:\")\n",
    "print(f\"hidden_dim={best[0]}, lambda={best[1]}, dropout={best[2]} -> RMSE={best[3]:.4f}, MAE={best[4]:.4f}, R²={best[5]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3cc89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
